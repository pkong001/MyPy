{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#### DEFINE\n",
    "output_name = \"0MATERIAL_ATTR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B2D.txt', 'B4P.txt', 'fucking_output.xlsx', 'SAPTableCompare.ipynb', 't1.txt', 'table1.txt']\n"
     ]
    }
   ],
   "source": [
    "with open(\"B2D.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    ecc_text = file.read()\n",
    "with open(\"B4P.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    hana_text = file.read()\n",
    "\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "def export_df(text):\n",
    "        ls = [i.strip() for i in text.split(\"\\n\") \n",
    "                if \n",
    "                        (\"Append structure \" not in i) \n",
    "                        and (\"Include structure \") not in i \n",
    "                        and (len(i) > 1)\n",
    "                ]\n",
    "        ls_ls = [i.split(\" \") for i in ls]\n",
    "\n",
    "        #####Define List\n",
    "        set1 = set([i[-2] for i in ls_ls]) # set2 =  set([i.split(\" \")[-3] for i in ls])\n",
    "        ls1 = [i for i in list(set1) if any(j.isalpha() for j in i)]\n",
    "        ls1.extend([\"QUAN\", \"DEC\"])\n",
    "        type_ls = list(set(ls1)) \n",
    "\n",
    "        ls_name = [ i[0] for i in ls_ls]\n",
    "\n",
    "        ls_type = []\n",
    "        for i in ls_ls:\n",
    "                if i[-2] in type_ls:\n",
    "                        ls_type.append(f'{i[-2]} {i[-1]}')\n",
    "                else:\n",
    "                        ls_type.append(f'{i[-3]} {i[-2]},{i[-1]}')\n",
    "\n",
    "\n",
    "        ls_combine = []\n",
    "        for i in range(0,len(ls_ls)):\n",
    "                ls_combine.append(f'{i} ' + ls_name[i]+\" \"+ls_type[i])\n",
    "        ls_combine_ls = [i.split(\" \") for i in ls_combine]\n",
    "        \n",
    "        return ls_combine_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#### Read files and apply def\n",
    "hana = export_df(hana_text)\n",
    "ecc = export_df(ecc_text)\n",
    "\n",
    "# Prepare Dataframe\n",
    "df_ecc = pd.DataFrame(data=ecc,columns=[\"e_index\",\"e_name\",\"e_type\",\"e_lgt\"])\n",
    "df_hana = pd.DataFrame(data=hana,columns=[\"h_index\",\"h_name\",\"h_type\",\"h_lgt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#### Check Field Mismatch\n",
    "ecc_name = set([i[1] for i in ecc])\n",
    "hana_name = set([i[1] for i in hana])\n",
    "\n",
    "ecc_u = []\n",
    "hana_u = []\n",
    "if ecc_name == hana_name:\n",
    "    print(\"Both DataFrames have the same columns.\")\n",
    "else:\n",
    "    for i in ecc_name - hana_name:\n",
    "        ecc_u.append(i)\n",
    "    for i in hana_name - ecc_name:\n",
    "        hana_u.append(i)\n",
    "\n",
    "# Make same lenght\n",
    "max_len = max(len(ecc_u), len(hana_u))\n",
    "ecc_u += [\"\"] * (max_len - len(ecc_u))  # Pad with empty string\n",
    "hana_u += [\"\"] * (max_len - len(hana_u))\n",
    "\n",
    "# Prepare Dataframe\n",
    "df_mismatched_fields = pd.DataFrame({\"Only in HANA\": hana_u,\"Only in ECC\": ecc_u})\n",
    "\n",
    "# print(df_mismatched_fields.to_string(index=False))  # Properly formatted DataFrame output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#### Check Type Mismatch\n",
    "ecc_dict = {row[1]: row for row in ecc}  # {C1: [...], C3: [...]}\n",
    "hana_dict = {row[1]: row for row in hana}  # {C1: [...], C3: [...]}\n",
    "matching_keys = set(ecc_dict.keys()) & set(hana_dict.keys())\n",
    "\n",
    "data = []\n",
    "for i in matching_keys:\n",
    "    e_row = ecc_dict[i]\n",
    "    h_row = hana_dict[i]\n",
    "    if (e_row[3] != h_row[3]) or (e_row[2] != h_row[2]):\n",
    "        data.append({\n",
    "            \"e_name\": e_row[1], \"e_type\": e_row[2], \"e_lgt\": e_row[3],\n",
    "            \"trans\": \">>>\",\n",
    "            \"h_name\": h_row[1], \"h_type\": h_row[2], \"h_lgt\": h_row[3]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_mismatched_types = pd.DataFrame(data)\n",
    "\n",
    "# print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file '0MATERIAL_ATTR.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Define Excel file path\n",
    "excel_path = f\"{output_name}.xlsx\"\n",
    "\n",
    "# Write to Excel with multiple sheets\n",
    "with pd.ExcelWriter(excel_path, engine=\"xlsxwriter\") as writer:\n",
    "    df_ecc.to_excel(writer, sheet_name=\"ecc\", index=False)\n",
    "    df_hana.to_excel(writer, sheet_name=\"hana\", index=False)\n",
    "    df_mismatched_types.to_excel(writer, sheet_name=\"mismatched_types\", index=False)\n",
    "    df_mismatched_fields.to_excel(writer, sheet_name=\"mismatched_fields\", index=False)\n",
    "\n",
    "\n",
    "print(f\"Excel file '{excel_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# ecc_ls = [i.strip() for i in ecc_text.split(\"\\n\") \n",
    "#             if \n",
    "#                 (\"Append structure \" not in i) \n",
    "#                 and (\"Include structure \") not in i \n",
    "#                 and (len(i) > 1)\n",
    "#         ]\n",
    "# ecc_ls_ls = [i.split(\" \") for i in ecc_ls]\n",
    "\n",
    "# #####Define List\n",
    "# set1 = set([i[-2] for i in ecc_ls_ls]) # set2 =  set([i.split(\" \")[-3] for i in ecc_ls])\n",
    "# ls1 = [i for i in list(set1) if i.isalpha()]\n",
    "# ls1.extend([\"QUAN\", \"DEC\"])\n",
    "# type_ls = list(set(ls1)) \n",
    "# # print(type_ls)\n",
    "\n",
    "# ecc_ls_name = [ i[0] for i in ecc_ls_ls]\n",
    "\n",
    "# ecc_ls_type = []\n",
    "# for i in ecc_ls_ls:\n",
    "#         if i[-2] in type_ls:\n",
    "#                 ecc_ls_type.append(f'{i[-2]} {i[-1]}')\n",
    "#         else:\n",
    "#                 ecc_ls_type.append(f'{i[-3]} {i[-2]} {i[-1]}')\n",
    "\n",
    "\n",
    "# ecc_ls_combine = []\n",
    "# for i in range(0,len(ecc_ls_ls)):\n",
    "#         ecc_ls_combine.append(f'{i} ' + ecc_ls_name[i]+\",\"+ecc_ls_type[i])\n",
    "\n",
    "#         ecc_ls = [i.strip() for i in hana_text.split(\"\\n\") \n",
    "#         if \n",
    "#             (\"Append structure \" not in i) \n",
    "#             and (\"Include structure \") not in i \n",
    "#             and (len(i) > 1)\n",
    "#     ]\n",
    "# ecc_ls_ls = [i.split(\" \") for i in ecc_ls]\n",
    "\n",
    "# #####Define List\n",
    "# set1 = set([i[-2] for i in ecc_ls_ls]) # set2 =  set([i.split(\" \")[-3] for i in ecc_ls])\n",
    "# ls1 = [i for i in list(set1) if i.isalpha()]\n",
    "# ls1.extend([\"QUAN\", \"DEC\"])\n",
    "# type_ls = list(set(ls1)) \n",
    "# # print(type_ls)\n",
    "\n",
    "# ecc_ls_name = [ i[0] for i in ecc_ls_ls]\n",
    "\n",
    "# ecc_ls_type = []\n",
    "# for i in ecc_ls_ls:\n",
    "#     if i[-2] in type_ls:\n",
    "#             ecc_ls_type.append(f'{i[-2]} {i[-1]}')\n",
    "#     else:\n",
    "#             ecc_ls_type.append(f'{i[-3]} {i[-2]} {i[-1]}')\n",
    "\n",
    "\n",
    "# ecc_ls_combine = []\n",
    "# for i in range(0,len(ecc_ls_ls)):\n",
    "#     ecc_ls_combine.append(f'{i} ' + ecc_ls_name[i]+\",\"+ecc_ls_type[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
